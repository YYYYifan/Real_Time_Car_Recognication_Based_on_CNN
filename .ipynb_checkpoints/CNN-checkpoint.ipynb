{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Check NVIDIA cuda status, and set default training device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.4.0\n",
      "Device: CUDA\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch Version: {}\".format(torch.__version__))\n",
    "\n",
    "device = \"CUDA\" if torch.cuda.is_available() else \"CPU\"\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Process\n",
    "\n",
    "Transform RGB images to grayscale, and extend image (from 1 -> 6)\n",
    "\n",
    "![extend](./images/extend_all_in_one.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0645, -1.2219]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import PIL\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "class imagePocess:\n",
    "    \n",
    "    def __init__(self, save: bool=True):\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        save : bool, optional\n",
    "            The value is control when this class func finish whether save the result.\n",
    "            Tue default is True\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "                \n",
    "        self.positivePath, self.negetivePath = self.getPath()        \n",
    "        \n",
    "        self.get_picture_path()\n",
    "        self.rotate()\n",
    "        self.split_images()\n",
    "        if save:\n",
    "            self.save()\n",
    "            \n",
    "    def getPath(self, front_viwe_path: str= \"./data/front_view.npy\"):\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        front_viwe_path : TYPE, optional\n",
    "            The path of .npy file(dictionary type)\n",
    "            The default is \"./data/front_view.npy\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        positivePath : TYPE\n",
    "            positive path list.\n",
    "        negetivePath : TYPE\n",
    "            negetive path list.\n",
    "\n",
    "        \"\"\"\n",
    "        front_viwe = np.load(front_viwe_path, allow_pickle=True).item()\n",
    "        \n",
    "        positivePath = front_viwe[\"81\"]  # NOTE: \"81\" is BMW\n",
    "        \n",
    "        negetivePath = []\n",
    "        for key, paths in front_viwe.items():\n",
    "            if key != \"81\":       \n",
    "                for path in paths:\n",
    "                    negetivePath.append(path)\n",
    "        \n",
    "        random.shuffle(negetivePath)\n",
    "        \n",
    "        negetivePath = negetivePath[:len(positivePath)]\n",
    "        \n",
    "        return positivePath, negetivePath\n",
    "    \n",
    "    \n",
    "    def get_picture_path(self):\n",
    "        \"\"\"\n",
    "        Transfrom label path (.txt) to image path (.png)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.image_paths = self.positivePath + self.negetivePath\n",
    "        \n",
    "        for index in range(len(self.image_paths)):\n",
    "            self.image_paths[index] = self.image_paths[index].replace(\"label\", \"image\").replace(\".txt\", \".jpg\")\n",
    "    \n",
    "    \n",
    "    def rotate(self):\n",
    "        \"\"\"\n",
    "        Rotate dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.images = []\n",
    "        for image_path in self.image_paths:\n",
    "            image = PIL.Image.open(image_path).convert(\"L\")\n",
    "            weight, height = image.size\n",
    "            \n",
    "            left_up = [0, 0, int(weight * 0.8), int(height * 0.8)]\n",
    "            left_down = [0, int(height * 0.2),  int(weight * 0.8), height]\n",
    "            right_up = [int(weight * 0.2), 0, weight, int(height * 0.8)]\n",
    "            right_down = [int(weight * 0.2), int(height * 0.2), weight, height]\n",
    "            center = [int(weight * 0.2), int(height * 0.2), int(weight * 0.8),int(height * 0.8)]\n",
    "            \n",
    "            self.images.append(image)\n",
    "            self.images.append(image.crop(center))\n",
    "            self.images.append(image.crop(left_up))\n",
    "            self.images.append(image.crop(left_down))\n",
    "            self.images.append(image.crop(right_up))\n",
    "            self.images.append(image.crop(right_down))\n",
    "            \n",
    "            \n",
    "    def split_images(self):\n",
    "        \"\"\"\n",
    "        Split images to train, verification. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        len_images = len(self.images)        \n",
    "        split_point = int(len_images/2)\n",
    "        print(\"len_images: {}, split: {}\".format(len_images, split_point))\n",
    "        positive = self.images[:split_point]\n",
    "        negetive = self.images[split_point:]\n",
    "        \n",
    "        \n",
    "        # print(\"Positive: {}, Negetive: {}\".format(len(positive), len(negetive)))        \n",
    "        \n",
    "        split_point = int(len(self.image_paths) / 2 * 0.8)\n",
    "        split_point = int(split_point * 6)\n",
    "        \n",
    "        \n",
    "        train_positive = positive[:split_point]\n",
    "        test_positive = positive[split_point:]\n",
    "        train_negetive = negetive[:split_point]\n",
    "        test_negetive = negetive[split_point:]\n",
    "        \n",
    "        '''\n",
    "        print(\"P_Train: {}, P_Verification: {}\\nT_Train: {}, T_Verification: {}\".format(\n",
    "            len(train_positive), len(train_negetive),\n",
    "            len(test_positive), len(test_negetive)\n",
    "            ))\n",
    "        '''\n",
    "        \n",
    "        self.train = train_positive + train_negetive\n",
    "        self.verification = test_positive + test_negetive\n",
    "        \n",
    "        # with open(\"./data/dataset/configure\", \"w\") as file_obj:\n",
    "            # file_obj.write(\"{} {}\".format(len(train_positive), len(test_positive)))\n",
    "            \n",
    "        with open(\"./parameter.json\", 'r') as file_obj:\n",
    "            parameter = json.load(file_obj)\n",
    "            \n",
    "        parameter[\"len_each_subset_in_train\"] = len(train_positive)\n",
    "        parameter[\"len_each_subset_in_verification\"] = len(test_positive)\n",
    "    \n",
    "        with open('./parameter.json', 'w') as file_obj:\n",
    "            json.dump(parameter, file_obj, sort_keys=True, indent=4, separators=(',', ':'))\n",
    "            \n",
    "        \n",
    "            \n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save result\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Train\n",
    "        buff = []\n",
    "        for image in self.train:\n",
    "            buff.append(np.asarray(image))\n",
    "\n",
    "        np.save(\"./data/dataset/train.npy\", buff)            \n",
    "        \n",
    "        # Verification\n",
    "        buff = []\n",
    "        for image in self.verification:\n",
    "            buff.append(np.asarray(image))\n",
    "\n",
    "        np.save(\"./data/dataset/verification.npy\", buff)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "Prepare dataset by using ***torch.utils.data.Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jul 19 06:29:35 2020\n",
    "\n",
    "@author: duyif\n",
    "\"\"\"\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class Mydataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images: dict, split_point: int):       \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        images : dict\n",
    "            dataset in dictionary type, and inside must be images.\n",
    "        split_point : int\n",
    "            where should split images to positive and negetive.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "        self.data = images\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((512,512)),\n",
    "                transforms.ToTensor()                \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.split_point = split_point\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return dataset length\n",
    "        \"\"\"\n",
    "        length = 0\n",
    "        for key, values in self.data.items():\n",
    "            for value in values:\n",
    "                length = length + 1\n",
    "                \n",
    "        return length\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : index\n",
    "            index of images.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : torch.tensor\n",
    "            image in tensor type\n",
    "        label : str\n",
    "            label of this image\n",
    "\n",
    "        \"\"\"\n",
    "        image = self.transform(self.data[index])        \n",
    "        label = 0 if index > self.split_point else 1 # \n",
    "    \n",
    "        return image, label        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = {\n",
    "        \"P\": [1, 2, 3],\n",
    "        \"N\": [4, 5]\n",
    "    }\n",
    "    \n",
    "    dataset = Mydataset(dataset, 1)\n",
    "    print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "epoch_size = 40\n",
    "learnRate = 0.001\n",
    "batch_size = 12\n",
    "\n",
    "with open(\"./parameter.json\", 'r') as file_obj:\n",
    "    parameter = json.load(file_obj)\n",
    "    len_each_subset_in_train = parameter[\"len_each_subset_in_train\"]\n",
    "\n",
    "\n",
    "myImage = prepare.imagePocess(save=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "# Load datas to torchvision.dataset .\n",
    "train_dataset = dataset.Mydataset(myImage.train, len_each_subset_in_train)\n",
    "# Load dataset to torchvision.dataloder .\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load Convorlotion Neural Network Models.\n",
    "net = models.MobileNetV2(2)\n",
    "net.to(device)\n",
    "\n",
    "# Define optimizer and loss func.\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learnRate, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Adjust learning rate by each epoch\n",
    "def adjust_learning_rate(optimizer, epoch, lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "print(\"Start Train\")\n",
    "with open(\"./result/train_torch_{}.log\".format(torch.__version__), \"w\") as log_obj:\n",
    "    start = datetime.datetime.now()\n",
    "    index_size = 0\n",
    "    for time in range(epoch_size):\n",
    "        adjust_learning_rate(optimizer, time, learnRate)\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        net.train(True)\n",
    "        for index, (image, labels) in enumerate(train_dataloader):\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # print(\"input shape\",image.shape)\n",
    "            outputs = net(image)\n",
    "            # print(outputs.shape,labels.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += outputs.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            Accuracy = correct/total\n",
    "            print(\"Epoch: {}/{}, idx:{} Loss:{:.4f} Accuracy:{:.4f}\".format(time +\n",
    "                                                                            1, epoch_size, index, loss, Accuracy))\n",
    "            logData = [time, index, loss.item(), Accuracy]\n",
    "            log_obj.write(str(logData))\n",
    "            log_obj.write(\"\\n\")\n",
    "\n",
    "        parameter[\"index_size\"] = index+1\n",
    "        parameter[\"batch_size\"] = time\n",
    "\n",
    "# Release video memory (if it`s available).\n",
    "torch.cuda.empty_cache()\n",
    "end = datetime.datetime.now()\n",
    "print(\"Train Time: {}\".format(end-start))\n",
    "\n",
    "# save model\n",
    "torch.save(net, './result/net_torch_{}.pkl'.format(torch.__version__))\n",
    "# save parameter.json\n",
    "with open('./parameter.json', 'w') as file_obj:\n",
    "    json.dump(parameter, file_obj, sort_keys=True,\n",
    "              indent=4, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import datetime\n",
    "import PIL\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "def numpy_to_PIL(images):\n",
    "    buff = []\n",
    "    for image in images:\n",
    "        buff.append(PIL.Image.fromarray(np.uint8(image)))\n",
    "    return buff        \n",
    "\n",
    "\n",
    "# Load parameters\n",
    "with open(\"./parameter.json\", 'r') as file_obj:\n",
    "    parameter = json.load(file_obj)\n",
    "    len_each_subset_in_verification = parameter[\"len_each_subset_in_verification\"]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load verification dataset.\n",
    "verification_images = np.load(\"./data/dataset/verification.npy\", allow_pickle=True)\n",
    "# Transfrom numpy type to PIL type\n",
    "verification_images = numpy_to_PIL(verification_images)\n",
    "\n",
    "print(\"Loading Net\")\n",
    "net = torch.load(\"./result/net_torch_{}.pkl\".format(torch.__version__))\n",
    "net.to(device)\n",
    "print(\"Finish\")\n",
    "\n",
    "\n",
    "print(\"Preparing images\")\n",
    "verification_dataset = Mydataset(verification_images, len_each_subset_in_verification)\n",
    "verification_dataloader = DataLoader(verification_dataset, batch_size=6, shuffle=True)\n",
    "print(\"Finish\")\n",
    "\n",
    "\n",
    "len_index = int(verification_dataset.__len__() / 6)\n",
    "total = 0\n",
    "correct = 0\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "with open(\"./result/verification.log\", \"w\") as file_obj:\n",
    "    with torch.no_grad():\n",
    "        for i,(image,labels) in enumerate(verification_dataloader):\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(image)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += outputs.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            log = \"idnex: {}/{}\".format(i+1, len_index)\n",
    "            print(log)\n",
    "            file_obj.write(log + \"\\n\")\n",
    "    \n",
    "    torch.cuda.empty_cache()   \n",
    "    cur_acc = correct / total\n",
    "    end = datetime.datetime.now()\n",
    "    total_time_cost = end - start\n",
    "    each_time_cost = total_time_cost / verification_dataset.__len__()\n",
    "    \n",
    "    log = \"\\nAccuracy:{:.4f}\\nTotal time cost: {}\\nEach image needs: {}\".format(correct / total, total_time_cost, each_time_cost)\n",
    "    print(log)\n",
    "    file_obj.write(log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization : Loss and Acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"./parameter.json\", 'r') as file_obj:\n",
    "    parameter = json.load(file_obj)\n",
    "    index_size = parameter[\"index_size\"]\n",
    "    batch_size = parameter[\"batch_size\"]\n",
    "\n",
    "with open(\"./result/train_torch_1.4.0.log\") as file_obj:\n",
    "    buffer = file_obj.readlines()\n",
    "\n",
    "for index in range(len(buffer)):\n",
    "    buffer[index] = buffer[index].replace(\"\\n\", \"\")\n",
    "    buffer[index] = buffer[index].replace(\",\", \"\")\n",
    "    buffer[index] = buffer[index].replace(\"[\", \"\")\n",
    "    buffer[index] = buffer[index].replace(\"]\", \"\")\n",
    "    buffer[index] = buffer[index].split(\" \")\n",
    "\n",
    "result_log = np.asarray(buffer).astype(float)\n",
    "\n",
    "loss = []\n",
    "for index in range(len(result_log)):\n",
    "    if index % index_size == 0:\n",
    "        loss.append(\n",
    "            np.sum(result_log[index: index + index_size, 2]) / index_size)\n",
    "\n",
    "loss = np.asarray(loss)\n",
    "\n",
    "accuarcy = []\n",
    "for index in range(len(result_log)):\n",
    "    if index % index_size == 0:\n",
    "        accuarcy.append(\n",
    "            np.sum(result_log[index: index + index_size, 3]) / index_size)\n",
    "\n",
    "accuarcy = np.asarray(accuarcy)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "acc, = plt.plot(range(1, len(accuarcy)+1), accuarcy)\n",
    "loss, = plt.plot(range(1, len(loss)+1), loss/batch_size)\n",
    "plt.legend((acc, loss), (\"Accuracy\", \"Loss\"))\n",
    "plt.title(\"Loss and Accuaray in Training\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "\n",
    "def to_percent(temp, position):\n",
    "    return '%1.0f' % (100*temp) + '%'\n",
    "\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(to_percent))\n",
    "\n",
    "plt.savefig(\"./images/Loss_and_Accuracy_in_Training.png\",\n",
    "            dpi=900,  bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time test in PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    " \n",
    "BOX=(0,25,880,640)\n",
    "\n",
    "# Determine whether the device uses CPU or GPU for calculation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "# Load convolution neural network model (trained)\n",
    "net = torch.load('../result/net_torch_{}.pkl'.format(torch.__version__))\n",
    "# Send model to GPU (if it is available)\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "while True:  \n",
    "    # Get image from scren\n",
    "    screen = np.array(ImageGrab.grab(bbox=BOX).convert(\"L\"))\n",
    "    # Use OpenCV2 to show the captured images \n",
    "    cv2.imshow(\"window\",screen)\n",
    "    # Turn off torch.autograd\n",
    "    with torch.no_grad():            \n",
    "        start = time.time()\n",
    "        # Transform PIL images to tensor (and to GPU if available)\n",
    "        screen = torch.from_numpy(screen).float().to(device)\n",
    "        # unsqueeze\n",
    "        screen = screen.unsqueeze(0).unsqueeze(0)\n",
    "        outputs = net(screen)\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        if predicted.item() == 0:\n",
    "            label = \"Others\"\n",
    "        elif predicted.item() == 1:\n",
    "            label = \"BMW\"\n",
    "        \n",
    "        print(\"{}\\t output: {}, time cost: {}\".format(\n",
    "            datetime.datetime.now(),\n",
    "            \"Others\" if predicted.item() == 0 else \"BMW\",\n",
    "            round(time.time()-start, 2)))\n",
    "        \n",
    "    # Display, exit by \"ESC\"\n",
    "    keyCode = cv2.waitKey(30) & 0xFF    \n",
    "    if keyCode == 27:    \n",
    "        torch.cuda.empty_cache()   \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time test in Jetson Nano\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from packages import camera\n",
    "import time\n",
    "import datetime\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "\n",
    "print(\"==========Prepare==========\")\n",
    "myCamera = camera.camera(grayscale=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "net = torch.load(\"./result/net_torch_1.4.0.pkl\")\n",
    "net = net.to(device)\n",
    "# Transfrom PIL images to tensor value\n",
    "P_to_T = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "print(\"==========Start==========\")\n",
    "window_handle = cv2.namedWindow(\"CSI Camera\", cv2.WINDOW_AUTOSIZE)\n",
    "while cv2.getWindowProperty(\"CSI Camera\", 0) >= 0:\n",
    "    image = myCamera.take_a_pic()\n",
    "    cv2.imshow(\"CSI Camera\", image)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        image = myCamera.take_a_pic()\n",
    "        # myCamera.save_pic(image)\n",
    "        image = P_to_T(image)\n",
    "        image = image.to(device)\n",
    "        image = image.unsqueeze(0)    \n",
    "\n",
    "        outputs = net(image)\n",
    "        _, predicted = outputs.max(1)\n",
    "        end = time.time()\n",
    "        time_cost = end - start    \n",
    "\n",
    "        print(\"{}\\t output: {}, time cost: {}\".format(\n",
    "            datetime.datetime.now(),\n",
    "            \"Others\" if predicted.item() == 0 else \"BMW\",\n",
    "            round(time.time()-start, 2)))\n",
    "        \n",
    "    # Display, exit by \"ESC\"\n",
    "    keyCode = cv2.waitKey(30) & 0xFF    \n",
    "    if keyCode == 27:\n",
    "        torch.cuda.empty_cache()   \n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
